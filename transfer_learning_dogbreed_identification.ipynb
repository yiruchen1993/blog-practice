{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transfer_learning_dogbreed_identification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPQmM5+VpXunFUheZ/P4p0Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yiruchen1993/tensorflow-practice/blob/master/transfer_learning_dogbreed_identification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63Aleo1shHe7"
      },
      "source": [
        "TODO: 增加訓練資料 (增加到3000會導致Ram不夠)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wa7jlujRz4wI",
        "outputId": "e74c533f-6414-4d8a-c6ac-e25c2b77c4b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive \n",
        "# 將 google drive 掛載在 colob\n",
        "drive.mount('/content/gdrive') "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOxSwYjZ0POa",
        "outputId": "e7a074ac-d10d-480f-89df-981749c57927",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd 'gdrive/My Drive/study/dogbreed'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/study/dogbreed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4IDb2Ym5o6v"
      },
      "source": [
        "import os\n",
        "import pickle"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8p3snJWKw_E"
      },
      "source": [
        "def pkl_save(pkl_filename, obj):\n",
        "    with open(pkl_filename, \"wb\") as file_write:\n",
        "        pickle.dump(obj, file_write)\n",
        "\n",
        "def pkl_load(pkl_filename):\n",
        "    with open(pkl_filename, \"rb\") as file_read:\n",
        "        obj = pickle.load(file_read)\n",
        "        return obj"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Hypzawm5emb",
        "outputId": "9c6eaafc-24e2-46ae-f63f-34b42d0b20b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "if not os.path.exists(\"dogbreed\"):\n",
        "    !unzip -u \"dog-breed-identification.zip\" -d \"dogbreed\"\n",
        "else:\n",
        "    print(\"data already exists\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data already exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-2pEEU51kNX",
        "outputId": "da894266-7259-4494-e562-0e599984572f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd 'dogbreed'"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/study/dogbreed/dogbreed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8e66Mseg3Sm7"
      },
      "source": [
        "import pandas as pd\n",
        "import cv2\n",
        "from os import walk\n",
        "import numpy as np"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZHxCHhT3h0k"
      },
      "source": [
        "y_label = pd.read_csv('labels.csv')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvnNGnGQ3sN5",
        "outputId": "93b6655e-1a80-4a0c-8d03-15d5b1ead576",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "if not os.path.exists(\"train_fig.pickle\"):\n",
        "    train_fig = []\n",
        "    for (dirpath, dirnames, filenames) in walk(\"./train/\"):\n",
        "        train_fig.extend(filenames)\n",
        "        break\n",
        "else:\n",
        "    print(\"train_fig already exists\")\n",
        "\n",
        "if not os.path.exists(\"test_fig.pickle\"):\n",
        "    test_fig = []\n",
        "    for (dirpath, dirnames, filenames) in walk(\"./test/\"):\n",
        "        test_fig.extend(filenames)\n",
        "        break\n",
        "else:\n",
        "    print(\"test_fig already exists\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_fig already exists\n",
            "test_fig already exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMh-K5hlwB75"
      },
      "source": [
        "# train_fig = pkl_load(\"train_fig.pickle\")\n",
        "# test_fig = pkl_load(\"test_fig.pickle\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqDsV2SnJZt6"
      },
      "source": [
        "width = 300"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUoGEfUvlRfe",
        "outputId": "4b9847db-1fda-4ba7-bce6-cf95f9962c67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "if not os.path.exists(\"x_train_raw.pickle\"):\n",
        "    x_train_raw = np.zeros((n_train, width, width, 3), dtype=np.uint8)\n",
        "    for i in range(n_train):\n",
        "        print(i)\n",
        "        image_path = \"./train/{}\".format(train_fig[i])\n",
        "        x_train_raw[i] = cv2.resize(cv2.imread(image_path, cv2.IMREAD_COLOR), (width, width))\n",
        "    pkl_save(\"x_train_raw.pickle\", x_train_raw)\n",
        "else:\n",
        "    print(\"x_train_raw already exists\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train_raw already exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36yyoaLLCzfY",
        "outputId": "5c306ac0-350b-4951-aa86-98aef3432303",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "if not os.path.exists(\"x_test_raw.pickle\"):\n",
        "    x_test_raw = np.zeros((n_test, width, width, 3), dtype=np.uint8)\n",
        "    for i in range(n_test):\n",
        "        print(i)\n",
        "        image_path = \"./test/{}\".format(test_fig[i])\n",
        "        x_test_raw[i] = cv2.resize(cv2.imread(image_path, cv2.IMREAD_COLOR), (width, width))\n",
        "    pkl_save(\"x_test_raw.pickle\", x_test_raw)\n",
        "else:\n",
        "    print(\"x_test_raw already exists\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_test_raw already exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_nDM_MGt80N"
      },
      "source": [
        "# x_train_raw = pkl_load(\"x_train_raw.pickle\")\n",
        "# x_test_raw = pkl_load(\"x_test_raw.pickle\")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-tmy5jCWu01"
      },
      "source": [
        "n_train = 2500\n",
        "n_test = 500"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pIChDx51SVA"
      },
      "source": [
        "# Normalize Data\n",
        "def normalize(X_train, X_test):\n",
        "    mean = np.mean(X_train, axis=(0, 1, 2, 3))\n",
        "    std = np.std(X_train, axis=(0, 1, 2, 3))\n",
        "    X_train = (X_train - mean) / (std + 1e-7)\n",
        "    X_test = (X_test - mean) / (std + 1e-7)\n",
        "    return X_train, X_test\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxHOjJpxUGHP"
      },
      "source": [
        "def get_training_data(is_retrain=False, n_train=3000, n_test=300):\n",
        "    if is_retrain:\n",
        "        x_train_raw = pkl_load(\"x_train_raw.pickle\")\n",
        "        # x_test_raw = pkl_load(\"x_test_raw.pickle\")\n",
        "\n",
        "        os.remove(\"x_train_raw_part.pickle\")\n",
        "        os.remove(\"x_test_raw_part.pickle\")\n",
        "\n",
        "        x_train_raw_part = x_train_raw[0:n_train, :, :, :]\n",
        "        pkl_save(\"x_train_raw_part.pickle\", x_train_raw_part)\n",
        "        x_test_raw_part = x_train_raw[n_train:(n_train+n_test), :, :, :]\n",
        "        pkl_save(\"x_test_raw_part.pickle\", x_test_raw_part)\n",
        "\n",
        "        del x_train_raw\n",
        "    else:\n",
        "        x_train_raw_part = pkl_load(\"x_train_raw_part.pickle\")\n",
        "        x_test_raw_part = pkl_load(\"x_test_raw_part.pickle\")\n",
        "    \n",
        "    # Normalize Training and Testset\n",
        "    x_train, x_test = normalize(x_train_raw_part, x_test_raw_part)\n",
        "    del x_train_raw_part\n",
        "    del x_test_raw_part\n",
        "\n",
        "    return x_train, x_test"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyjQ1NI8V2nK"
      },
      "source": [
        "x_train, x_test = get_training_data(is_retrain=True, n_train=n_train, n_test=n_test)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AB2tNTHYw7L7"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn import preprocessing"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8XEX2NC8CBU"
      },
      "source": [
        "# y_train = np.array(y_label.breed)\n",
        "y_label_all = np.array(y_label.breed)\n",
        "\n",
        "# One-hot\n",
        "labelen = preprocessing.LabelEncoder()\n",
        "y_label_all = labelen.fit_transform(y_label_all)\n",
        "onehotencoder = OneHotEncoder()\n",
        "y_label_all_onehot = onehotencoder.fit_transform(y_label_all.reshape(-1, 1)).toarray()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fz8yVqiAhztp"
      },
      "source": [
        "y_train = y_label_all_onehot[0:n_train]\n",
        "y_test = y_label_all[n_train:(n_train+n_test)]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctRNIlAxBic8"
      },
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D, Input\n",
        "from keras.preprocessing import image\n",
        "from keras import backend as K\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import shutil"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2ZZUGKdWYk-"
      },
      "source": [
        "def get_trained_model(x_train, y_train, is_retrain=False):\n",
        "    if is_retrain:\n",
        "        if os.path.exists(\"trained_model\"):\n",
        "            shutil.rmtree(\"trained_model\")\n",
        "        os.mkdir(\"trained_model\")\n",
        "\n",
        "        input_tensor = Input(shape=(32, 32, 3))\n",
        "        \n",
        "        # include top 決定要不要加入 fully Connected Layer\n",
        "        \"\"\"Resnet 50 架構\"\"\"\n",
        "        model = keras.applications.ResNet50(\n",
        "            input_shape=(32, 32, 3),\n",
        "            include_top=False,\n",
        "            weights=\"imagenet\",\n",
        "            pooling=None,\n",
        "            classes=120,\n",
        "        )\n",
        "        # model.summary()\n",
        "\n",
        "        # 添加層數\n",
        "        x = model.output\n",
        "        x = GlobalAveragePooling2D()(x)\n",
        "        x = Dense(units=128, activation=\"relu\")(x)\n",
        "        x = Dropout(rate=0.1)(x)\n",
        "        predictions = Dense(units=120, activation=\"softmax\")(x)\n",
        "        model = Model(inputs=model.input, outputs=predictions)\n",
        "        print(\"Model depth：\", len(model.layers))\n",
        "\n",
        "        # 鎖定特定幾層不要更新權重\n",
        "        for layer in model.layers[:100]:\n",
        "            layer.trainable = False\n",
        "        for layer in model.layers[100:]:\n",
        "            layer.trainable = True\n",
        "\n",
        "        model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "        model.fit(x_train, y_train, batch_size=32, epochs=20)\n",
        "\n",
        "        model.save(\"trained_model\")    \n",
        "    else:\n",
        "        model = keras.models.load_model(\"trained_model\")\n",
        "    \n",
        "    print(model)\n",
        "    return model"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_ezZO_MXGJX",
        "outputId": "2f42dcc6-4849-4f43-aebe-a27ffec51e6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = get_trained_model(x_train, y_train, is_retrain=True)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model depth： 179\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 32, 32, 3) for input Tensor(\"input_2:0\", shape=(None, 32, 32, 3), dtype=float32), but it was called on an input with incompatible shape (None, 300, 300, 3).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 32, 32, 3) for input Tensor(\"input_2:0\", shape=(None, 32, 32, 3), dtype=float32), but it was called on an input with incompatible shape (None, 300, 300, 3).\n",
            "79/79 [==============================] - 22s 283ms/step - loss: 4.8102 - accuracy: 0.0056\n",
            "Epoch 2/20\n",
            "79/79 [==============================] - 22s 278ms/step - loss: 4.7859 - accuracy: 0.0120\n",
            "Epoch 3/20\n",
            "79/79 [==============================] - 22s 280ms/step - loss: 4.7842 - accuracy: 0.0148\n",
            "Epoch 4/20\n",
            "79/79 [==============================] - 23s 285ms/step - loss: 4.7823 - accuracy: 0.0140\n",
            "Epoch 5/20\n",
            "79/79 [==============================] - 23s 289ms/step - loss: 4.7806 - accuracy: 0.0140\n",
            "Epoch 6/20\n",
            "79/79 [==============================] - 23s 292ms/step - loss: 4.7793 - accuracy: 0.0120\n",
            "Epoch 7/20\n",
            "79/79 [==============================] - 23s 294ms/step - loss: 4.7763 - accuracy: 0.0156\n",
            "Epoch 8/20\n",
            "79/79 [==============================] - 23s 297ms/step - loss: 4.7711 - accuracy: 0.0128\n",
            "Epoch 9/20\n",
            "79/79 [==============================] - 24s 299ms/step - loss: 4.7652 - accuracy: 0.0152\n",
            "Epoch 10/20\n",
            "79/79 [==============================] - 24s 299ms/step - loss: 4.7602 - accuracy: 0.0132\n",
            "Epoch 11/20\n",
            "79/79 [==============================] - 24s 301ms/step - loss: 4.7529 - accuracy: 0.0112\n",
            "Epoch 12/20\n",
            "79/79 [==============================] - 24s 301ms/step - loss: 4.7500 - accuracy: 0.0140\n",
            "Epoch 13/20\n",
            "79/79 [==============================] - 24s 301ms/step - loss: 4.7437 - accuracy: 0.0136\n",
            "Epoch 14/20\n",
            "79/79 [==============================] - 24s 303ms/step - loss: 4.7374 - accuracy: 0.0136\n",
            "Epoch 15/20\n",
            "79/79 [==============================] - 24s 304ms/step - loss: 4.7313 - accuracy: 0.0140\n",
            "Epoch 16/20\n",
            "79/79 [==============================] - 24s 305ms/step - loss: 4.7302 - accuracy: 0.0140\n",
            "Epoch 17/20\n",
            "79/79 [==============================] - 24s 305ms/step - loss: 4.7273 - accuracy: 0.0152\n",
            "Epoch 18/20\n",
            "79/79 [==============================] - 24s 305ms/step - loss: 4.7201 - accuracy: 0.0128\n",
            "Epoch 19/20\n",
            "79/79 [==============================] - 24s 304ms/step - loss: 4.7214 - accuracy: 0.0144\n",
            "Epoch 20/20\n",
            "79/79 [==============================] - 24s 304ms/step - loss: 4.7147 - accuracy: 0.0152\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "INFO:tensorflow:Assets written to: trained_model/assets\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f27aa3bfd30>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFn1HEK7ez0t",
        "outputId": "8c7ac16a-861a-4e2a-a32e-c10bc598443d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_pred = model.predict(x_test)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 32, 32, 3) for input Tensor(\"input_2:0\", shape=(None, 32, 32, 3), dtype=float32), but it was called on an input with incompatible shape (None, 300, 300, 3).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAhz32VAfzCL"
      },
      "source": [
        "y_pred_label = np.argmax(y_pred, axis=1)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ownZISzEgeXy",
        "outputId": "92602faf-2dcb-4dd0-e145-251b013603e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sum(y_test == y_pred_label)/n_test"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.01"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    }
  ]
}